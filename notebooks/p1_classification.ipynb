{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Classification Dünnschnabelmöwen und Dickhornschafe\n",
    "\n",
    "Author: Nils Bestehorn\n",
    "\n",
    "Matrikelnummer: 1242890"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from mpl_toolkits.mplot3d import Axes3D #gehört zu matplotlib.pyplot\n",
    "import seaborn as sns\n",
    "#import mpl_toolkits.mplot3d\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Funktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.figure()\n",
    "    \n",
    "    plt.plot(history.history['loss'], label='Trainings Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    \n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoche')\n",
    "    plt.ylabel('Loss (MSE)')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_losses(history1,history2, model1_name=\"\",model2_name=\"\"):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Plot 1\n",
    "    axes[0].plot(history1.history['loss'], label='Trainings Loss')\n",
    "    axes[0].plot(history1.history['val_loss'], label='Validation Loss')\n",
    "\n",
    "    axes[0].set_title(f'Training und Validierung {model1_name}')\n",
    "    axes[0].set_xlabel('Epoche')\n",
    "    axes[0].set_ylabel('Loss (Binary Crossentropy)')\n",
    "\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Plot 2\n",
    "    axes[1].plot(history2.history['loss'], label='Trainings Loss')\n",
    "    axes[1].plot(history2.history['val_loss'], label='Validation Loss')\n",
    "\n",
    "    axes[1].set_title(f'Training und Validierung {model2_name}')\n",
    "    axes[1].set_xlabel('Epoche')\n",
    "    axes[1].set_ylabel('Loss (Binary Crossentropy)')\n",
    "\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_decision_background_from_df(model,df,ax,feature_cols,step=0.02,alpha=0.25):\n",
    "    X = df[feature_cols].to_numpy() \n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.arange(x_min, x_max, step),\n",
    "        np.arange(y_min, y_max, step)\n",
    "    )\n",
    "\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    probs = model.predict(grid, verbose=0)\n",
    "    Z = (probs > 0.5).astype(int).reshape(xx.shape)\n",
    "\n",
    "    ax.contourf(\n",
    "        xx, yy, Z,\n",
    "        alpha=alpha,\n",
    "        levels=[-0.5, 0.5, 1.5],\n",
    "        colors=[\"#6fa8dc\", \"#e06666\"]  # blau / rot\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_decision_background(model,X,ax,step=0.02,padding=5,alpha=0.25):\n",
    "    \"\"\"plot_decision_background\\n\n",
    "        model=>DL Model\\n\n",
    "        X = df_source[[\"Groesse\", \"Umfang\"]].to_numpy() \n",
    "    \"\"\"\n",
    "    # Bereich festlegen\n",
    "    x_min, x_max = X[:, 0].min() - padding, X[:, 0].max() + padding\n",
    "    y_min, y_max = X[:, 1].min() - padding, X[:, 1].max() + padding\n",
    "\n",
    "    # Gitter erzeugen\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.arange(x_min, x_max, step),\n",
    "        np.arange(y_min, y_max, step)\n",
    "    )\n",
    "\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    probs = model.predict(grid, verbose=0)\n",
    "    Z = (probs > 0.5).astype(int).reshape(xx.shape)\n",
    "\n",
    "    ax.contourf(\n",
    "        xx, yy, Z,\n",
    "        alpha=alpha,\n",
    "        levels=[-0.5, 0.5, 1.5],\n",
    "        colors=[\"#6fa8dc\", \"#e06666\"]  # blau / rot\n",
    "    )\n",
    "\n",
    "def plot_classes_2_models(model1,model2, model1_name=\"\",model2_name=\"\"):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Plot 1\n",
    "    axes[0].plot(history1.history['loss'], label='Trainings Loss')\n",
    "    axes[0].plot(history1.history['val_loss'], label='Validation Loss')\n",
    "\n",
    "    axes[0].set_title(f'Training und Validierung {model1_name}')\n",
    "    axes[0].set_xlabel('Epoche')\n",
    "    axes[0].set_ylabel('Loss (Binary Crossentropy)')\n",
    "\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Plot 2\n",
    "    axes[1].plot(history2.history['loss'], label='Trainings Loss')\n",
    "    axes[1].plot(history2.history['val_loss'], label='Validation Loss')\n",
    "\n",
    "    axes[1].set_title(f'Training und Validierung {model2_name}')\n",
    "    axes[1].set_xlabel('Epoche')\n",
    "    axes[1].set_ylabel('Loss (Binary Crossentropy)')\n",
    "\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## More Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Daten Laden und eine Übersicht über die Daten verschaffen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebooks_folder = os.getcwd()\n",
    "projekt_folder = os.path.dirname(notebooks_folder)\n",
    "source_data=os.path.join(projekt_folder,\"data\",\"animals.csv\")\n",
    "\n",
    "df_source=pd.read_csv(source_data)\n",
    "df_source.info()\n",
    "#print(df_source.info())\n",
    "print()\n",
    "print(\"Nan Check:\")\n",
    "print(df_source.isna().sum())\n",
    "print()\n",
    "print(\"Übersicht Über alle Daten:\")\n",
    "print(df_source.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source.head(5)\n",
    "#print(df_source.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Label Typen Testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_types=df_source['Label'].unique()\n",
    "print(label_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Label 1 (Duennschnabelmoewe) Übersicht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source[df_source['Label']==label_types[0]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Label 2 (Dickhornschaf) Übersicht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source[df_source['Label']==label_types[1]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Übersichts Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolesche Masken\n",
    "mask_schaf = df_source[\"Label\"] == \"Dickhornschaf\"\n",
    "mask_moewe = df_source[\"Label\"] == \"Duennschnabelmoewe\"\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(\n",
    "    df_source.loc[mask_schaf, \"Groesse\"],\n",
    "    df_source.loc[mask_schaf, \"Umfang\"],\n",
    "    color=\"red\",\n",
    "    label=\"Dickhornschaf\",\n",
    "    edgecolor=\"k\"\n",
    ")\n",
    "plt.scatter(\n",
    "    df_source.loc[mask_moewe, \"Groesse\"],\n",
    "    df_source.loc[mask_moewe, \"Umfang\"],\n",
    "    color=\"blue\",\n",
    "    label=\"Dünnschnabelmöwe\",\n",
    "    edgecolor=\"k\"\n",
    ")\n",
    "plt.xlabel(\"Größe\")\n",
    "plt.ylabel(\"Umfang\")\n",
    "plt.title(\"Tiere nach Größe und Umfang\")\n",
    "plt.legend()\n",
    "plt.margins(x=0.1, y=0.1)\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#plt.figure(figsize=(8, 6))\n",
    "#sns.scatterplot(\n",
    "#    data=df_source,\n",
    "#    x=\"Groesse\",\n",
    "#    y=\"Umfang\",\n",
    "#    hue=\"Label\",\n",
    "#    style=\"Label\",\n",
    "#    alpha=0.7\n",
    "#)\n",
    "#plt.title(\"Tiere nach Größe und Umfang\")\n",
    "#plt.xlabel(\"Größe\")\n",
    "#plt.ylabel(\"Umfang\")\n",
    "#plt.grid(True)\n",
    "#plt.margins(x=0.1, y=0.1)\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# Preprocess the Data\n",
    "Kodiere die Labels als numerische Werte, damit sie von\n",
    "Tensorflow verarbeitet werden können. Erstellung einer classen map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = {label: idx for idx, label in enumerate(label_types)}\n",
    "print(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_source=df_source.rename(columns={\"Label\":\"Tiername\"})\n",
    "df_source[\"Label_encoded\"] = df_source[\"Label\"].map(class_name)\n",
    "assert df_source[\"Label_encoded\"].isna().sum() == 0\n",
    "df_source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot hier nicht nötig!!!\n",
    "df_source_test=df_source.copy()\n",
    "df_source_test[\"Duennschnabelmoewe\"] = (\n",
    "    df_source_test[\"Label\"] == \"Duennschnabelmoewe\"\n",
    ").astype(int)\n",
    "\n",
    "df_source_test[\"Dickhornschaf\"] = (\n",
    "    df_source_test[\"Label\"] == \"Dickhornschaf\"\n",
    ").astype(int)\n",
    "df_source_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Unnötigen Speicher freigeben!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del df_source_test\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Splitting Data\n",
    "80% Training, 20% Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_source.copy()\n",
    "df.pop('Label') #Label vorher wegwerfen\n",
    "\n",
    "train_dataset = df.sample(frac=0.8, random_state=SEED)\n",
    "test_dataset = df.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Setting Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop('Label_encoded')\n",
    "#train_labels_names = train_features.pop('Label')\n",
    "\n",
    "test_labels = test_features.pop('Label_encoded')\n",
    "#test_labels_names = test_features.pop('Label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.describe().transpose()[['mean', 'std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = tf.keras.layers.Normalization(axis=-1) #feature weise normelarisierung\n",
    "normalizer.adapt(np.array(train_features))\n",
    "print(\"Features Normalized!\")\n",
    "print(normalizer.mean.numpy())\n",
    "print()\n",
    "\n",
    "first = np.array(train_features[:1])\n",
    "with np.printoptions(precision=2, suppress=True):\n",
    "  print('First example:', first)\n",
    "  print()\n",
    "  print('Normalized:', normalizer(first).numpy())\n",
    "\n",
    "#Speicher für alle Ergebnisse wenn mehrere Modelle getestet\n",
    "np.array(normalizer(train_features)).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "# Build the Model\n",
    "Erstelle in Keras ein Modell mit 2 Hidden Layers\n",
    "mit jeweils 4 Knoten und Relu-Aktivierung. Der Output-Knoten soll die Sigmoid-\n",
    "Funktion als Aktivierung haben. Nimm Binary Cross Entropy als Loss-Funktion, und den\n",
    "Adam-Optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model(norm=None):\n",
    "  if norm:\n",
    "    print(\"Model with Normalization selected\")\n",
    "    model = keras.Sequential([\n",
    "        norm,\n",
    "        layers.Dense(4, activation='relu'),\n",
    "        layers.Dense(4, activation='relu'),\n",
    "        layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "  else:\n",
    "    print(\"Model without Normalization selected\")\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(4, activation='relu'),\n",
    "        layers.Dense(4, activation='relu'),\n",
    "        layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    #Calls sind hier gleich!\n",
    "  model.compile(#loss='binarycrossentropy',\n",
    "                loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                #optimizer='adam',\n",
    "                metrics=[\"accuracy\"],\n",
    "                optimizer=keras.optimizers.Adam(0.001)\n",
    "                )\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = {}\n",
    "dnn_model = build_and_compile_model()\n",
    "dnn_model_large_epochs = build_and_compile_model()\n",
    "dnn_model_norm = build_and_compile_model(normalizer)\n",
    "dnn_model_norm_large_epochs = build_and_compile_model(normalizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## Train the Models\n",
    "Trainiere das Modell 50 (eventuell mehr) Epochen lang, mit einer\n",
    "Batch-Größe von 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "### Base Model (dnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dnn_model = dnn_model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    epochs=50,\n",
    "    batch_size=100,\n",
    "    validation_split=0.2,\n",
    "    verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model.summary()\n",
    "test_results['dnn_model'] = dnn_model.evaluate(\n",
    "    test_features, test_labels,\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "### Base Model Large Epochs (dnn_model_large_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dnn_model_large_epochs = dnn_model_large_epochs.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    epochs=500,\n",
    "    batch_size=100,\n",
    "    validation_split=0.2,\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model_large_epochs.summary()\n",
    "test_results['dnn_model_large_epochs'] = dnn_model_large_epochs.evaluate(\n",
    "    test_features, test_labels,\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "### Base Model Normalized (dnn_model_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dnn_model_norm = dnn_model_norm.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    epochs=50,\n",
    "    batch_size=100,\n",
    "    validation_split=0.2,\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model_norm.summary()\n",
    "test_results['dnn_model_norm'] = dnn_model_norm.evaluate(\n",
    "    test_features, test_labels,\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "### Base Model Normalized Large Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dnn_model_norm_large_epochs = dnn_model_norm_large_epochs.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    epochs=500,\n",
    "    batch_size=100,\n",
    "    validation_split=0.2,\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model_norm_large_epochs.summary()\n",
    "test_results['dnn_model_norm_large_epochs'] = dnn_model_norm_large_epochs.evaluate(\n",
    "    test_features, test_labels,\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "# Validate the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test_results)\n",
    "results_df=pd.DataFrame(test_results, index=['loss','accuracy']).T\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.plot(kind=\"bar\", figsize=(8,5))\n",
    "plt.title(\"Modellvergleich auf dem Testset\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(history_dnn_model,history_dnn_model_large_epochs,model1_name=\"dnn_model\",model2_name=\"dnn_model_large_epochs\")\n",
    "plot_losses(history_dnn_model_norm,history_dnn_model_norm_large_epochs,model1_name=\"dnn_model_norm\",model2_name=\"dnn_model_norm_large_epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "Plotte die Loss-Funktion über Training und Test. \n",
    "Wie unterscheidet sich der Verlauf für wenige und viele Epochen?\n",
    "\n",
    "- Die Modelle mit Wenig Epochen sind noch weiter weg zu den Trainings Kurven wärend durch mehr Epochen sich die Validation dem Training annähert!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bereich festlegen\n",
    "x_min, x_max = df_source[\"Groesse\"].min() - 5, df_source[\"Groesse\"].max() + 5\n",
    "y_min, y_max = df_source[\"Umfang\"].min() - 5, df_source[\"Umfang\"].max() + 5\n",
    "\n",
    "# Gitter erzeugen\n",
    "xx, yy = np.meshgrid(\n",
    "    np.linspace(x_min, x_max, 300),\n",
    "    np.linspace(y_min, y_max, 300)\n",
    ")\n",
    "\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "pred_probs = dnn_model_norm_large_epochs.predict(grid, verbose=0)\n",
    "pred_classes = (pred_probs > 0.5).astype(int)\n",
    "X = pred_classes.reshape(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_source[[\"Groesse\", \"Umfang\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plot_decision_background(dnn_model, X, axes[0],step=0.1, padding=10)\n",
    "axes[0].scatter(\n",
    "    df_source.loc[mask_schaf, \"Groesse\"],\n",
    "    df_source.loc[mask_schaf, \"Umfang\"],\n",
    "    color=\"red\",\n",
    "    label=\"Dickhornschaf\",\n",
    "    edgecolor=\"k\"\n",
    ")\n",
    "axes[0].scatter(\n",
    "    df_source.loc[mask_moewe, \"Groesse\"],\n",
    "    df_source.loc[mask_moewe, \"Umfang\"],\n",
    "    color=\"blue\",\n",
    "    label=\"Dünnschnabelmöwe\",\n",
    "    edgecolor=\"k\"\n",
    ")\n",
    "axes[0].set_xlabel(\"Größe\")\n",
    "axes[0].set_ylabel(\"Umfang\")\n",
    "axes[0].set_title(\"Modell-Entscheidungsfläche (dnn_model)\")\n",
    "axes[0].legend()\n",
    "plot_decision_background(dnn_model_large_epochs, X, axes[1],step=0.1, padding=10)\n",
    "axes[1].scatter(\n",
    "    df_source.loc[mask_schaf, \"Groesse\"],\n",
    "    df_source.loc[mask_schaf, \"Umfang\"],\n",
    "    color=\"red\",\n",
    "    label=\"Dickhornschaf\",\n",
    "    edgecolor=\"k\"\n",
    ")\n",
    "axes[1].scatter(\n",
    "    df_source.loc[mask_moewe, \"Groesse\"],\n",
    "    df_source.loc[mask_moewe, \"Umfang\"],\n",
    "    color=\"blue\",\n",
    "    label=\"Dünnschnabelmöwe\",\n",
    "    edgecolor=\"k\"\n",
    ")\n",
    "axes[1].set_xlabel(\"Größe\")\n",
    "axes[1].set_ylabel(\"Umfang\")\n",
    "axes[1].set_title(\"Modell-Entscheidungsfläche (dnn_model_large_epochs)\")\n",
    "axes[1].legend()\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plot_decision_background(dnn_model_norm, X, axes[0],step=0.1, padding=10)\n",
    "axes[0].scatter(\n",
    "    df_source.loc[mask_schaf, \"Groesse\"],\n",
    "    df_source.loc[mask_schaf, \"Umfang\"],\n",
    "    color=\"red\",\n",
    "    label=\"Dickhornschaf\",\n",
    "    edgecolor=\"k\"\n",
    ")\n",
    "axes[0].scatter(\n",
    "    df_source.loc[mask_moewe, \"Groesse\"],\n",
    "    df_source.loc[mask_moewe, \"Umfang\"],\n",
    "    color=\"blue\",\n",
    "    label=\"Dünnschnabelmöwe\",\n",
    "    edgecolor=\"k\"\n",
    ")\n",
    "axes[0].set_xlabel(\"Größe\")\n",
    "axes[0].set_ylabel(\"Umfang\")\n",
    "axes[0].set_title(\"Modell-Entscheidungsfläche (dnn_model_norm)\")\n",
    "axes[0].legend()\n",
    "plot_decision_background(dnn_model_norm_large_epochs, X, axes[1],step=0.1, padding=10)\n",
    "axes[1].scatter(\n",
    "    df_source.loc[mask_schaf, \"Groesse\"],\n",
    "    df_source.loc[mask_schaf, \"Umfang\"],\n",
    "    color=\"red\",\n",
    "    label=\"Dickhornschaf\",\n",
    "    edgecolor=\"k\"\n",
    ")\n",
    "axes[1].scatter(\n",
    "    df_source.loc[mask_moewe, \"Groesse\"],\n",
    "    df_source.loc[mask_moewe, \"Umfang\"],\n",
    "    color=\"blue\",\n",
    "    label=\"Dünnschnabelmöwe\",\n",
    "    edgecolor=\"k\"\n",
    ")\n",
    "axes[1].set_xlabel(\"Größe\")\n",
    "axes[1].set_ylabel(\"Umfang\")\n",
    "axes[1].set_title(\"Modell-Entscheidungsfläche (dnn_model_norm_large_epochs)\")\n",
    "axes[1].legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "## Prediction on new Data\n",
    "Berechne zuletzt die Vorhersagewerte des Modells für folgende Wertepaare:\n",
    "Umfang/Groesse: [90, 90], [70, 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "daten = [\n",
    "    [90, 90],\n",
    "    [70, 70]\n",
    "]\n",
    "\n",
    "prediction_data = pd.DataFrame(daten, columns=['Umfang', 'Groesse'])\n",
    "prediction_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_to_df(models, X, threshold=0.5):\n",
    "    \"\"\"\n",
    "    models: dict {name: keras_model}\n",
    "    X: DataFrame oder numpy array\n",
    "    \"\"\"\n",
    "    df = X.copy()\n",
    "\n",
    "    for name, model in models.items():\n",
    "        probs = model.predict(X, verbose=0).ravel()\n",
    "        df[f\"{name}_prob\"] = probs\n",
    "        df[f\"{name}_class\"] = (probs > threshold).astype(int)\n",
    "\n",
    "    return df\n",
    "models = {\n",
    "    \"base\": dnn_model,\n",
    "    \"many_epochs\": dnn_model_large_epochs,\n",
    "    \"norm\": dnn_model_norm,\n",
    "    \"norm_many_epochs\": dnn_model_norm_large_epochs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = predict_to_df(models, prediction_data)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.filter(like=\"_prob\").style.background_gradient(\n",
    "    cmap=\"coolwarm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plot_decision_background(dnn_model, X, axes[0],step=0.1, padding=20)\n",
    "axes[0].scatter(\n",
    "    df_source.loc[mask_schaf, \"Groesse\"],\n",
    "    df_source.loc[mask_schaf, \"Umfang\"],\n",
    "    color=\"red\",\n",
    "    label=\"Dickhornschaf\",\n",
    "    edgecolor=\"k\"\n",
    ")\n",
    "axes[0].scatter(\n",
    "    df_source.loc[mask_moewe, \"Groesse\"],\n",
    "    df_source.loc[mask_moewe, \"Umfang\"],\n",
    "    color=\"blue\",\n",
    "    label=\"Dünnschnabelmöwe\",\n",
    "    edgecolor=\"k\"\n",
    ")\n",
    "\n",
    "axes[0].scatter(\n",
    "    results_df[\"Groesse\"],\n",
    "    results_df[\"Umfang\"],\n",
    "    facecolors=\"white\",\n",
    "    edgecolors=\"black\",\n",
    "    label=\"Prediction Data\"\n",
    ")\n",
    "\n",
    "axes[0].set_xlabel(\"Größe\")\n",
    "axes[0].set_ylabel(\"Umfang\")\n",
    "axes[0].set_title(\"Modell-Entscheidungsfläche (dnn_model)\")\n",
    "axes[0].legend()\n",
    "plot_decision_background(dnn_model_large_epochs, X, axes[1],step=0.1, padding=20)\n",
    "axes[1].scatter(\n",
    "    df_source.loc[mask_schaf, \"Groesse\"],\n",
    "    df_source.loc[mask_schaf, \"Umfang\"],\n",
    "    color=\"red\",\n",
    "    label=\"Dickhornschaf\",\n",
    "    edgecolor=\"k\"\n",
    ")\n",
    "axes[1].scatter(\n",
    "    df_source.loc[mask_moewe, \"Groesse\"],\n",
    "    df_source.loc[mask_moewe, \"Umfang\"],\n",
    "    color=\"blue\",\n",
    "    label=\"Dünnschnabelmöwe\",\n",
    "    edgecolor=\"k\"\n",
    ")\n",
    "axes[1].scatter(\n",
    "    results_df[\"Groesse\"],\n",
    "    results_df[\"Umfang\"],\n",
    "    facecolors=\"white\",\n",
    "    edgecolors=\"black\",\n",
    "    label=\"Prediction Data\"\n",
    ")\n",
    "\n",
    "axes[1].set_xlabel(\"Größe\")\n",
    "axes[1].set_ylabel(\"Umfang\")\n",
    "axes[1].set_title(\"Modell-Entscheidungsfläche (dnn_model_large_epochs)\")\n",
    "axes[1].legend()\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plot_decision_background(dnn_model_norm, X, axes[0],step=0.1, padding=20)\n",
    "axes[0].scatter(\n",
    "    df_source.loc[mask_schaf, \"Groesse\"],\n",
    "    df_source.loc[mask_schaf, \"Umfang\"],\n",
    "    color=\"red\",\n",
    "    label=\"Dickhornschaf\",\n",
    "    edgecolor=\"k\"\n",
    ")\n",
    "axes[0].scatter(\n",
    "    df_source.loc[mask_moewe, \"Groesse\"],\n",
    "    df_source.loc[mask_moewe, \"Umfang\"],\n",
    "    color=\"blue\",\n",
    "    label=\"Dünnschnabelmöwe\",\n",
    "    edgecolor=\"k\"\n",
    ")\n",
    "axes[0].scatter(\n",
    "    results_df[\"Groesse\"],\n",
    "    results_df[\"Umfang\"],\n",
    "    facecolors=\"white\",\n",
    "    edgecolors=\"black\",\n",
    "    label=\"Prediction Data\"\n",
    ")\n",
    "\n",
    "axes[0].set_xlabel(\"Größe\")\n",
    "axes[0].set_ylabel(\"Umfang\")\n",
    "axes[0].set_title(\"Modell-Entscheidungsfläche (dnn_model_norm)\")\n",
    "axes[0].legend()\n",
    "plot_decision_background(dnn_model_norm_large_epochs, X, axes[1],step=0.1, padding=20)\n",
    "axes[1].scatter(\n",
    "    df_source.loc[mask_schaf, \"Groesse\"],\n",
    "    df_source.loc[mask_schaf, \"Umfang\"],\n",
    "    color=\"red\",\n",
    "    label=\"Dickhornschaf\",\n",
    "    edgecolor=\"k\"\n",
    ")\n",
    "axes[1].scatter(\n",
    "    df_source.loc[mask_moewe, \"Groesse\"],\n",
    "    df_source.loc[mask_moewe, \"Umfang\"],\n",
    "    color=\"blue\",\n",
    "    label=\"Dünnschnabelmöwe\",\n",
    "    edgecolor=\"k\"\n",
    ")\n",
    "\n",
    "axes[1].scatter(\n",
    "    results_df[\"Groesse\"],\n",
    "    results_df[\"Umfang\"],\n",
    "    facecolors=\"white\",\n",
    "    edgecolors=\"black\",\n",
    "    label=\"Prediction Data\"\n",
    ")\n",
    "axes[1].set_xlabel(\"Größe\")\n",
    "axes[1].set_ylabel(\"Umfang\")\n",
    "axes[1].set_title(\"Modell-Entscheidungsfläche (dnn_model_norm_large_epochs)\")\n",
    "axes[1].legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning-uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
