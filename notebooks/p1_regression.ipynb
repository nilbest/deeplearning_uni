{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Regression Agrarwissenschaften und Ernte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from mpl_toolkits.mplot3d import Axes3D #gehört zu matplotlib.pyplot\n",
    "import seaborn as sns\n",
    "#import mpl_toolkits.mplot3d\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Helper Funktions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'], label='Training loss')\n",
    "    \n",
    "    if 'val_loss' in history.history:\n",
    "        plt.plot(history.history['val_loss'], label='Test loss')\n",
    "    \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss (Mean Squared Error)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss_german(history):\n",
    "    plt.figure()\n",
    "    \n",
    "    plt.plot(history.history['loss'], label='Trainings Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Test Loss')\n",
    "    \n",
    "    plt.title('Training und Test Loss')\n",
    "    plt.xlabel('Epoche')\n",
    "    plt.ylabel('Verlust (Mean Squared Error)')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebooks_folder = os.getcwd()\n",
    "projekt_folder = os.path.dirname(notebooks_folder)\n",
    "source_data=os.path.join(projekt_folder,\"data\",\"harvest.csv\")\n",
    "\n",
    "df_source=pd.read_csv(source_data)\n",
    "df_source.info()\n",
    "#print(df_source.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111,projection=\"3d\")\n",
    "\n",
    "ax.scatter(\n",
    "    df_source[\"Dünger\"],\n",
    "    df_source[\"Niederschlag\"],\n",
    "    df_source[\"Ertrag\"]\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Dünger\")\n",
    "ax.set_ylabel(\"Niederschlag\")\n",
    "ax.set_zlabel(\"Ertrag\")\n",
    "ax.set_title(\"3D-Plot der Ertragsdaten\")\n",
    "ax.set_box_aspect(None, zoom=0.85)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_source,\n",
    "    x=\"Dünger\",\n",
    "    y=\"Ertrag\",\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(\"Dünger vs. Ertrag\")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_source,\n",
    "    x=\"Niederschlag\",\n",
    "    y=\"Ertrag\",\n",
    "    ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(\"Niederschlag vs. Ertrag\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source.isna().sum()\n",
    "#dataset = dataset.dropna() #nicht nötig da kein Nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Splitting Data in Train & Test\n",
    "seperate Data sets for learning 80% Training, 20% Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = df_source.sample(frac=0.8, random_state=0)\n",
    "test_dataset = df_source.drop(train_dataset.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Set the Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_dataset[[\"Dünger\", \"Niederschlag\"]]\n",
    "test_features  = test_dataset[[\"Dünger\", \"Niederschlag\"]]\n",
    "\n",
    "train_labels = train_dataset[\"Ertrag\"]\n",
    "test_labels  = test_dataset[\"Ertrag\"]\n",
    "\n",
    "#Alternative\n",
    "#train_features = train_dataset.copy()\n",
    "#test_features = test_dataset.copy()\n",
    "\n",
    "#train_labels = train_features.pop('Ertrag')\n",
    "#test_labels = test_features.pop('Ertrag')\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.describe().transpose()[['mean', 'std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(np.array(train_features))\n",
    "print(\"Features Normalized!\")\n",
    "print(normalizer.mean.numpy())\n",
    "print()\n",
    "\n",
    "first = np.array(train_features[:1])\n",
    "with np.printoptions(precision=2, suppress=True):\n",
    "  print('First example:', first)\n",
    "  print()\n",
    "  print('Normalized:', normalizer(first).numpy())\n",
    "\n",
    "#Speicher für alle Ergebnisse wenn mehrere Modelle getestet\n",
    "test_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# Regression with deep neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Build the model Function!\n",
    "Erstelle in Keras ein Modell mit 2 Hidden Layers mit\n",
    "jeweils 4 Knoten und Relu-Aktivierung. Nimm den Mean Squared Error als Loss-\n",
    "Funktion, und den Adam-Optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model(norm):\n",
    "  model = keras.Sequential([\n",
    "      norm,\n",
    "      layers.Dense(4, activation='relu'),\n",
    "      layers.Dense(4, activation='relu'),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  model.compile(loss='mean_squared_error',\n",
    "                optimizer='adam')#tf.keras.optimizers.Adam(0.001))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model = build_and_compile_model(normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Model ist Build yet!\n",
    "dnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Traing des Models\n",
    "Trainiere das Modell 100 Epochen lang, mit einer\n",
    "Batch-Größe von 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = dnn_model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    epochs=100,\n",
    "    batch_size=50,\n",
    "    validation_split=0.2)#,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_german(history)\n",
    "#plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results['dnn_model'] = dnn_model.evaluate(test_features, test_labels, verbose=0)\n",
    "\n",
    "# Vorhersagen für Trainings- und Testdaten\n",
    "#train_predictions = dnn_model.predict(train_features)\n",
    "#test_predictions  = dnn_model.predict(test_features)\n",
    "#pd.DataFrame(test_results, index=['Mean absolute error [MPG]']).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wertebereich aus den Daten\n",
    "duenger_range = np.linspace(df_source[\"Dünger\"].min(), df_source[\"Dünger\"].max(), 30)\n",
    "niederschlag_range = np.linspace(df_source[\"Niederschlag\"].min(), df_source[\"Niederschlag\"].max(), 30)\n",
    "\n",
    "D, N = np.meshgrid(duenger_range, niederschlag_range)\n",
    "\n",
    "# Grid in DataFrame-Form bringen\n",
    "grid = np.column_stack([D.ravel(), N.ravel()])\n",
    "\n",
    "Z = dnn_model.predict(grid).reshape(D.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "train_scatter=ax.scatter(\n",
    "    train_features[\"Dünger\"],\n",
    "    train_features[\"Niederschlag\"],\n",
    "    train_labels,\n",
    "    color=\"blue\",\n",
    "    label=\"Training Daten\",\n",
    "    alpha=0.6\n",
    ")\n",
    "\n",
    "test_scatter=ax.scatter(\n",
    "    test_features[\"Dünger\"],\n",
    "    test_features[\"Niederschlag\"],\n",
    "    test_labels,\n",
    "    color=\"green\",\n",
    "    label=\"Test Daten\",\n",
    "    alpha=0.6\n",
    ")\n",
    "\n",
    "ax.plot_surface(\n",
    "    D, N, Z,\n",
    "    color=\"red\",\n",
    "    alpha=0.4\n",
    ")\n",
    "\n",
    "\n",
    "# Proxy für Fläche\n",
    "surface_proxy= Patch(\n",
    "    facecolor=\"red\",\n",
    "    edgecolor=\"red\",\n",
    "    alpha=0.4,\n",
    "    label=\"Vorhersage\"\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Dünger\")\n",
    "ax.set_ylabel(\"Niederschlag\")\n",
    "ax.set_zlabel(\"Ertrag\")\n",
    "ax.set_title(\"3D Plot der Ertragsdaten und Modellvorhersagen\")\n",
    "\n",
    "ax.legend(handles=[\n",
    "    train_scatter,\n",
    "    test_scatter,\n",
    "    surface_proxy\n",
    "])\n",
    "#ax.legend()\n",
    "ax.set_box_aspect(None, zoom=0.85)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## Predictions on the test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = dnn_model.predict(test_features).flatten()\n",
    "\n",
    "a = plt.axes(aspect='equal')\n",
    "plt.scatter(test_labels, test_predictions)\n",
    "plt.xlabel('True Values ')\n",
    "plt.ylabel('Predictions ')\n",
    "lims = [-1, 8]\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "_ = plt.plot(lims, lims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "## Prediction on new Data\n",
    "Berechne zuletzt die Vorhersagewerte des Modells für folgende Wertepaare:\n",
    "Niederschlag/Dünger: [0.25, 0.25], [0.85, 0.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "daten=[\n",
    "    [0.25, 0.25], \n",
    "    [0.85, 0.75]\n",
    "]\n",
    "\n",
    "prediction_data = pd.DataFrame(daten, columns=['Niederschlag', 'Dünger'])\n",
    "prediction_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dnn_model.predict(prediction_data)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Speichern\n",
    "dnn_model.save('dnn_model_ertrag.keras')\n",
    "\n",
    "#Laden\n",
    "#reloaded = tf.keras.models.load_model('dnn_model.keras')\n",
    "\n",
    "#wenn weiter trainieren interessant!\n",
    "#history = reloaded.fit(\n",
    "#    train_features,\n",
    "#    train_labels,\n",
    "#    epochs=100,\n",
    "#    batch_size=50,\n",
    "#    validation_split=0.2)\n",
    "\n",
    "#test_results['reloaded'] = reloaded.evaluate(\n",
    "#    test_features, test_labels, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning-uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
