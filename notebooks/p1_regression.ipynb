{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Regression Agrarwissenschaften und Ernte\n",
    "\n",
    "Author: Nils Bestehorn\n",
    "\n",
    "Matrikelnummer: 1242890\n",
    "\n",
    "Als Agrarwissenschaftler:in möchten Sie ein Modell entwickeln, das den Ernteertrag eines\n",
    "bestimmten Feldes basierend auf ausgebrachtem Dünger (in Kilogramm pro Hektar) und der\n",
    "durchschnittlichen Niederschlagsmenge während der Wachstumsperiode (in Millimetern)\n",
    "vorhersagen kann. Ihre Forschung konzentriert sich auf die Optimierung landwirtschaftlicher\n",
    "Erträge durch Vorhersagemodelle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from mpl_toolkits.mplot3d import Axes3D #gehört zu matplotlib.pyplot\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "#\n",
    "import keras #Durch diese Art des Imports erkennt VS Code alle keras befehle richtig! Weniger nutzen der Docs nötig!\n",
    "#print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Helper Funktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'], label='Training loss')\n",
    "    \n",
    "    if 'val_loss' in history.history:\n",
    "        plt.plot(history.history['val_loss'], label='Test loss')\n",
    "    \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss (Mean Squared Error)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss_german(history):\n",
    "    plt.figure()\n",
    "    \n",
    "    plt.plot(history.history['loss'], label='Trainings Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Test Loss')\n",
    "    \n",
    "    plt.title('Training und Test Loss')\n",
    "    plt.xlabel('Epoche')\n",
    "    plt.ylabel('Verlust (Mean Squared Error)')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Daten laden & visualisieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Laden der Daten aus einem Unterordner namens \"daten\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebooks_folder = os.getcwd()\n",
    "projekt_folder = os.path.dirname(notebooks_folder)\n",
    "source_data=os.path.join(projekt_folder,\"data\",\"harvest.csv\")\n",
    "\n",
    "df_source=pd.read_csv(source_data)\n",
    "df_source.info()\n",
    "#print(df_source.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111,projection=\"3d\")\n",
    "\n",
    "ax.scatter(\n",
    "    df_source[\"Dünger\"],\n",
    "    df_source[\"Niederschlag\"],\n",
    "    df_source[\"Ertrag\"]\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Dünger [kg/ha]\")\n",
    "ax.set_ylabel(\"Niederschlag [mm]\")\n",
    "ax.set_zlabel(\"Ertrag\")\n",
    "ax.set_title(\"3D-Plot der Ertragsdaten\")\n",
    "ax.set_box_aspect(None, zoom=0.85)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cProfile import label\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_source,\n",
    "    x=\"Dünger\",\n",
    "    y=\"Ertrag\",\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(\"Dünger vs. Ertrag\")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_source,\n",
    "    x=\"Niederschlag\",\n",
    "    y=\"Ertrag\",\n",
    "    ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(\"Niederschlag vs. Ertrag\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Cleanup der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Auf Nan's prüfen, um gegebenenfalls diese zu eliminieren. (hier nicht nötig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source.isna().sum()\n",
    "#dataset = dataset.dropna() #nicht nötig da kein Nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Splitting der Daten in Train & Test\n",
    "Split auf 80% Trainingsdaten und 20% Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "SEED = 42 #Eigentlich nur Nötig da sonnst keine Zufalls Zahlen Generation! Macht das immer das gleiche zufalls Split der Daten passiert!\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "#seed_gen = keras.random.SeedGenerator(SEED) # Nutzbar in den Layern! für Dropout; Random Initializer; Data Augmentation\n",
    "#tf.random.set_seed(SEED) # für reproduzierbares Training; identische Gewichte; GPU-Determinismus \n",
    "\n",
    "train_dataset = df_source.sample(frac=0.8, random_state=SEED) # Zufalls Split der Daten\n",
    "test_dataset = df_source.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Die Labels & Features setzen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_dataset[[\"Dünger\", \"Niederschlag\"]]\n",
    "test_features  = test_dataset[[\"Dünger\", \"Niederschlag\"]]\n",
    "train_labels = train_dataset[\"Ertrag\"]\n",
    "test_labels  = test_dataset[\"Ertrag\"]\n",
    "\n",
    "#Alternative\n",
    "#train_features = train_dataset.copy()\n",
    "#test_features = test_dataset.copy()\n",
    "#train_labels = train_features.pop('Ertrag')\n",
    "#test_labels = test_features.pop('Ertrag')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Normalisierung der Daten\n",
    "Immer gut für Modelle, da sie so besser und effektiver lernen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.describe().transpose()[['mean', 'std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(np.array(train_features))\n",
    "print(\"Features Normalized!\")\n",
    "print(normalizer.mean.numpy())\n",
    "print()\n",
    "\n",
    "first = np.array(train_features[:1])\n",
    "with np.printoptions(precision=2, suppress=True):\n",
    "  print('First example:', first)\n",
    "  print()\n",
    "  print('Normalized:', normalizer(first).numpy())\n",
    "\n",
    "#Speicher für alle Ergebnisse wenn mehrere Modelle getestet\n",
    "test_results = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Regression with deep neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Build the model Function!\n",
    "Erstelle in Keras ein Modell mit 2 Hidden Layers mit\n",
    "jeweils 4 Knoten und Relu-Aktivierung. Nimm den Mean Squared Error als Loss-\n",
    "Funktion, und den Adam-Optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model(norm) -> keras.Model:\n",
    "  model = keras.Sequential([\n",
    "      norm,\n",
    "      keras.layers.Dense(4, activation='relu'),\n",
    "      keras.layers.Dense(4, activation='relu'),\n",
    "      keras.layers.Dense(1)\n",
    "  ])\n",
    "    #Es gibt mehrere Aufrufmöglichkeiten! Professioneller für finetuning ist durch Klassen oder Funktionen nicht über Strg lookups\n",
    "  model.compile(loss=keras.losses.MeanSquaredError(),#'mean_squared_error',\n",
    "                optimizer=keras.optimizers.Adam())#'adam')#tf.keras.optimizers.Adam(0.001))\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model = build_and_compile_model(normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Model ist Build yet!\n",
    "#dnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Training des Models\n",
    "Trainiere das Modell 100 Epochen lang, mit einer\n",
    "Batch-Größe von 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = dnn_model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    epochs=100,\n",
    "    batch_size=50,\n",
    "    validation_split=0.2,verbose=0)\n",
    "dnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_german(history)\n",
    "#plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results['dnn_model'] = dnn_model.evaluate(test_features, test_labels, verbose=0)\n",
    "\n",
    "# Vorhersagen für Trainings- und Testdaten\n",
    "#train_predictions = dnn_model.predict(train_features)\n",
    "#test_predictions  = dnn_model.predict(test_features)\n",
    "#pd.DataFrame(test_results, index=['Mean absolute error [MPG]']).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wertebereich aus den Daten\n",
    "duenger_range = np.linspace(df_source[\"Dünger\"].min(), df_source[\"Dünger\"].max(), 30)\n",
    "niederschlag_range = np.linspace(df_source[\"Niederschlag\"].min(), df_source[\"Niederschlag\"].max(), 30)\n",
    "D, N = np.meshgrid(duenger_range, niederschlag_range)\n",
    "\n",
    "# Grid in DataFrame-Form bringen\n",
    "grid = np.column_stack([D.ravel(), N.ravel()])\n",
    "Z = dnn_model.predict(grid).reshape(D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "train_scatter=ax.scatter(\n",
    "    train_features[\"Dünger\"],\n",
    "    train_features[\"Niederschlag\"],\n",
    "    train_labels,\n",
    "    color=\"blue\",\n",
    "    label=\"Training Daten\",\n",
    "    alpha=0.6\n",
    ")\n",
    "\n",
    "test_scatter=ax.scatter(\n",
    "    test_features[\"Dünger\"],\n",
    "    test_features[\"Niederschlag\"],\n",
    "    test_labels,\n",
    "    color=\"green\",\n",
    "    label=\"Test Daten\",\n",
    "    alpha=0.6\n",
    ")\n",
    "\n",
    "ax.plot_surface(\n",
    "    D, N, Z,\n",
    "    color=\"red\",\n",
    "    alpha=0.4\n",
    ")\n",
    "\n",
    "\n",
    "# Proxy für Fläche\n",
    "surface_proxy= Patch(\n",
    "    facecolor=\"red\",\n",
    "    edgecolor=\"red\",\n",
    "    alpha=0.4,\n",
    "    label=\"Vorhersage\"\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Dünger\")\n",
    "ax.set_ylabel(\"Niederschlag\")\n",
    "ax.set_zlabel(\"Ertrag\")\n",
    "ax.set_title(\"3D Plot der Ertragsdaten und Modellvorhersagen\")\n",
    "\n",
    "ax.legend(handles=[\n",
    "    train_scatter,\n",
    "    test_scatter,\n",
    "    surface_proxy\n",
    "])\n",
    "#ax.legend()\n",
    "ax.set_box_aspect(None, zoom=0.85)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### Prediction (Vorhersage) auf das Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = dnn_model.predict(test_features).flatten()\n",
    "\n",
    "a = plt.axes(aspect='equal')\n",
    "plt.scatter(test_labels, test_predictions)\n",
    "plt.xlabel('True Values ')\n",
    "plt.ylabel('Predictions ')\n",
    "lims = [-1, 8]\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "_ = plt.plot(lims, lims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "### Prediction (Vorhersage) auf neue unbekannte Daten\n",
    "Berechne zuletzt die Vorhersagewerte des Modells für folgende Wertepaare:\n",
    "Niederschlag/Dünger: [0.25, 0.25], [0.85, 0.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "daten=[\n",
    "    [0.25, 0.25], \n",
    "    [0.85, 0.75]\n",
    "]\n",
    "\n",
    "prediction_data = pd.DataFrame(daten, columns=['Niederschlag', 'Dünger'])\n",
    "prediction_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dnn_model.predict(prediction_data)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_to_df(models:dict[str,keras.Model], X):#, threshold=0.5):\n",
    "    \"\"\"\n",
    "    models: dict {name: keras_model}\n",
    "    X: DataFrame oder numpy array\n",
    "    \"\"\"\n",
    "    df = X.copy()\n",
    "\n",
    "    for name, model in models.items():\n",
    "        probs = model.predict(X, verbose=0).ravel()\n",
    "        df[f\"{name}_prediction\"] = probs\n",
    "        #df[f\"{name}_class\"] = (probs > threshold).astype(int)\n",
    "\n",
    "    return df\n",
    "models = {\n",
    "    \"base\": dnn_model\n",
    "}\n",
    "results_df = predict_to_df(models, prediction_data)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Speichern des Models\n",
    "#dnn_model.save('dnn_model_ertrag.keras')\n",
    "\n",
    "#Laden\n",
    "#reloaded = tf.keras.models.load_model('dnn_model.keras')\n",
    "\n",
    "#wenn weiter trainieren interessant!\n",
    "#history = reloaded.fit(\n",
    "#    train_features,\n",
    "#    train_labels,\n",
    "#    epochs=100,\n",
    "#    batch_size=50,\n",
    "#    validation_split=0.2)\n",
    "\n",
    "#test_results['reloaded'] = reloaded.evaluate(\n",
    "#    test_features, test_labels, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning-uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
